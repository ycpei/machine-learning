{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from numpy import *\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import minimize\n",
    "import pickle\n",
    "\n",
    "# data retrieval\n",
    "\n",
    "def getIiter(ifname):\n",
    "    \"\"\"\n",
    "    Get the iterator from a csv file with filename ifname\n",
    "    \"\"\"\n",
    "    ifile = open(ifname, 'r')\n",
    "    iiter = csv.reader(ifile)\n",
    "    iiter.__next__()\n",
    "    return iiter\n",
    "\n",
    "def getRow(iiter):\n",
    "    \"\"\"\n",
    "    Get one line from a csv iterator\n",
    "    \"\"\"\n",
    "    return parseRow(iiter.__next__())\n",
    "\n",
    "def parseRow(s):\n",
    "    y = [int(x) for x in s]\n",
    "    lab = y[0]\n",
    "    z = y[1:]\n",
    "    return lab, z\n",
    "\n",
    "def getRows(n, iiter):\n",
    "    \"\"\"\n",
    "    Get the first n rows\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    for i in range(n):\n",
    "        x.append(getRow(iiter))\n",
    "    return x\n",
    "\n",
    "def getAllRows(ifname):\n",
    "    iiter = getIiter(ifname)\n",
    "    x = []\n",
    "    l = []\n",
    "    for row in iiter:\n",
    "        lab, z = parseRow(row)\n",
    "        x.append(z)\n",
    "        l.append(lab)\n",
    "    return x, l\n",
    "\n",
    "def cutData(x):\n",
    "    \"\"\"\n",
    "    70% training\n",
    "    30% testing\n",
    "    \"\"\"\n",
    "    m = len(x)\n",
    "    t = int(m * .7)\n",
    "    return x[:t], x[t:]\n",
    "\n",
    "def num2IndMat(l):\n",
    "    t = array(l)\n",
    "    tt = [vectorize(int)((t == i)) for i in range(10)]\n",
    "    return array(tt).T\n",
    "\n",
    "def scaleX(x):\n",
    "    return multiply(x, 1/255)\n",
    "\n",
    "def addOnes(x):\n",
    "    m, n = shape(x)\n",
    "    #newX = ones((m, n + 1))\n",
    "    #newX[:,1:] = x\n",
    "    return hstack((ones((m, 1)), x))\n",
    "\n",
    "def readData(ifname):\n",
    "    x, l = getAllRows(ifname)\n",
    "    return scaleX(x), num2IndMat(l), l\n",
    "\n",
    "def readData1(ifname):\n",
    "    x, y, l = readData(ifname)\n",
    "    trainX, testX = cutData(x)\n",
    "    trainY, testY = cutData(y)\n",
    "    trainL, testL = cutData(l)\n",
    "    return trainX, trainY, trainL, testX, testY, testL\n",
    "\n",
    "# sigmoid\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + e ** (-x))\n",
    "\n",
    "def sigDot(a, theta):\n",
    "    return sigmoid(dot(addOnes(a), theta))\n",
    "\n",
    "def hTheta(theta1, theta2, x):\n",
    "    \"\"\"\n",
    "    the result fo feedforward\n",
    "    \"\"\"\n",
    "    a2 = sigDot(x, theta1)\n",
    "    a3 = sigDot(a2, theta2)\n",
    "    return addOnes(a2), a3\n",
    "\n",
    "def costFunFromA(theta1, theta2, a3, y, lambd):\n",
    "    #print(shape(a3), shape(y))\n",
    "    return - sum(1 / m * (y * log(a3) + (1 - y) * log (1 - a3)))\\\n",
    "           + sum(lambd / 2 / m * (theta1[1:] * theta1[1:])) + sum(lambd / 2 / m * (theta2[1:] * theta2[1:]))\n",
    "\n",
    "def gradFromA(theta1, theta2, a1, a2, a3, y, lambd):\n",
    "    dd1 = zeros((n1 + 1, n2))\n",
    "    dd2 = zeros((n2 + 1, n3))\n",
    "    for i in range(m):\n",
    "        d3 = (a3[i] - y[i]).reshape((1, n3))\n",
    "        d2 = (dot(d3, theta2.T) * a2[i] * (1 - a2[i])).reshape((1, n2 + 1))\n",
    "        dd2 += a2[i].reshape((n2 + 1, 1)) * d3\n",
    "        dd1 += (a1[i].reshape((n1 + 1, 1)) * d2)[:,1:]\n",
    "    dd1[1:] += lambd * theta1[1:]\n",
    "    dd2[1:] += lambd * theta2[1:]\n",
    "    dd1 /= m\n",
    "    dd2 /= m\n",
    "    return dd1, dd2\n",
    "\n",
    "#def dSigmoid(x):\n",
    "    #\"\"\"\n",
    "    #the derivative of the sigmoid function\n",
    "    #\"\"\"\n",
    "    #sx = sigmoid(x)\n",
    "    #return sx * (1 - sx)\n",
    "\n",
    "def costFunAndGrad(theta1, theta2, x, y, lambd):\n",
    "    a2, a3 = hTheta(theta1, theta2, x)\n",
    "    a1 = addOnes(x)\n",
    "    return costFunFromA(theta1, theta2, a3, y, lambd), gradFromA(theta1, theta2, a1, a2, a3, y, lambd)\n",
    "\n",
    "def costFunAndGradTheta(theta, x, y, lambd):\n",
    "    theta1, theta2 = unpack(theta)\n",
    "    c, (dd1, dd2) = costFunAndGrad(theta1, theta2, x, y, lambd)\n",
    "    return c, pack(dd1, dd2)\n",
    "\n",
    "def pack(x1, x2):\n",
    "    return hstack((x1.reshape(x1.size), x2.reshape(x2.size)))\n",
    "\n",
    "def unpack(x):\n",
    "    return x[:(n1 + 1) * n2].reshape((n1 + 1, n2)), x[(n1 + 1) * n2:].reshape((n2 + 1, n3))\n",
    "\n",
    "def train(theta1, theta2, x, y, lambd):\n",
    "    theta = pack(theta1, theta2)\n",
    "    return minimize(costFunAndGradTheta, theta, args=(x, y, lambd),\n",
    "                   jac=True, method=\"CG\", options={\"maxiter\": maxiter, \"disp\": True})\n",
    "\n",
    "def predict(theta1, theta2, x):\n",
    "    _, a3 = hTheta(theta1, theta2, x)\n",
    "    return argmax(a3, axis=1)\n",
    "\n",
    "def accuracy(theta1, theta2, x, l):\n",
    "    t = (predict(theta1, theta2, x) == l)\n",
    "    return sum(t) / size(t)\n",
    "    \n",
    "def randomizeTheta(m, n):\n",
    "    epsilon = sqrt(6) / (sqrt(m) + sqrt(n))\n",
    "    #print(epsilon)\n",
    "    return 2 * epsilon * random.rand(m, n) - epsilon\n",
    "\n",
    "def readSubData(ifname):\n",
    "    iiter = getIiter(ifname)\n",
    "    return scaleX(array([[int(y) for y in row] for row in iiter]))\n",
    "\n",
    "def writeRows(ofname, l):\n",
    "    f = open(ofname, 'w')\n",
    "    f.write('ImageId,Label\\n')\n",
    "    for i, ll in enumerate(l):\n",
    "        f.write(str(i + 1))\n",
    "        f.write(',')\n",
    "        f.write(str(ll))\n",
    "        f.write('\\n')\n",
    "    f.close\n",
    "\n",
    "def saveTheta(ofname, theta1, theta2):\n",
    "    pf = open(ofname, 'wb')\n",
    "    pickle.dump((theta1, theta2), pf)\n",
    "    pf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, trainY, trainL, testX, testY, testL = readData1('train.csv')\n",
    "subX = readSubData('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.348283\n",
      "         Iterations: 100\n",
      "         Function evaluations: 202\n",
      "         Gradient evaluations: 202\n",
      "0.967005680465\n",
      "0.948178715975\n"
     ]
    }
   ],
   "source": [
    "m, n1 = shape(trainX)\n",
    "n2 = 25\n",
    "n3 = 10\n",
    "#initTheta1 = zeros((n1 + 1, n2))\n",
    "#initTheta2 = zeros((n2 + 1, n3))\n",
    "initTheta1 = randomizeTheta(n1 + 1, n2)\n",
    "initTheta2 = randomizeTheta(n2 + 1, n3)\n",
    "lambd = 3\n",
    "maxiter = 100\n",
    "#theta = pack(initTheta1, initTheta2)\n",
    "#print(costFunAndGrad(initTheta1, initTheta2, trainX, trainY, lambd))\n",
    "res = train(initTheta1, initTheta2, trainX, trainY, lambd)\n",
    "theta1, theta2 = unpack(res.x)\n",
    "\n",
    "print(accuracy(theta1, theta2, trainX, trainL))\n",
    "print(accuracy(theta1, theta2, testX, testL))\n",
    "subL = predict(theta1, theta2, subX)\n",
    "writeRows('submission.csv', subL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveTheta('theta_nn_100_1.pkl', theta1, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.306500\n",
      "         Iterations: 100\n",
      "         Function evaluations: 202\n",
      "         Gradient evaluations: 202\n",
      "0.981121806864\n",
      "0.952305372589\n"
     ]
    }
   ],
   "source": [
    "res = train(theta1, theta2, trainX, trainY, lambd)\n",
    "theta1, theta2 = unpack(res.x)\n",
    "\n",
    "print(accuracy(theta1, theta2, trainX, trainL))\n",
    "print(accuracy(theta1, theta2, testX, testL))\n",
    "subL = predict(theta1, theta2, subX)\n",
    "writeRows('submission.csv', subL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- random initial theta, no regularization, conjugate gradient, 100 iterations; advanced 105 places on the leaderboard; scored 0.93971, which is an improvement of your previous score of 0.91214; now ranking 1701 out of 2012\n",
    "- same as above, but 200 iterations. Showing signs of overfitting: 0.984421238818 for training and 0.947226410602 for testing. You advanced 11 places on the leaderboard! Your submission scored 0.94142, which is an improvement of your previous score of 0.93971. Great job!\n",
    "- with lambda = 3, 100 iterations; 0.967005680465 0.948178715975; Your Best Entry  You advanced 9 places on the leaderboard! Your submission scored 0.94328, which is an improvement of your previous score of 0.94142. Great job! 1683 out of 2015\n",
    "- same as above but 200 iterations: 0.981121806864 0.952305372589 Your Best Entry  You advanced 37 places on the leaderboard! Your submission scored 0.95114, which is an improvement of your previous score of 0.94328. Great job! now 1646 out of 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
